{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM"
      ],
      "metadata": {
        "id": "pqZ8qe8CGF2X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pLwcUX4Cxek",
        "outputId": "ed5ed14f-d22a-479c-ae21-55efc85ed101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "69/69 [==============================] - 2s 4ms/step - loss: 0.2412\n",
            "Epoch 2/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1302\n",
            "Epoch 3/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1185\n",
            "Epoch 4/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1174\n",
            "Epoch 5/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1174\n",
            "Epoch 6/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1149\n",
            "Epoch 7/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1136\n",
            "Epoch 8/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1142\n",
            "Epoch 9/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1114\n",
            "Epoch 10/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1101\n",
            "Epoch 11/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1098\n",
            "Epoch 12/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1088\n",
            "Epoch 13/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1080\n",
            "Epoch 14/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1076\n",
            "Epoch 15/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1060\n",
            "Epoch 16/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1058\n",
            "Epoch 17/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1058\n",
            "Epoch 18/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1050\n",
            "Epoch 19/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1046\n",
            "Epoch 20/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1040\n",
            "Epoch 21/100\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.1040\n",
            "Epoch 22/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1037\n",
            "Epoch 23/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1031\n",
            "Epoch 24/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1032\n",
            "Epoch 25/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1028\n",
            "Epoch 26/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1027\n",
            "Epoch 27/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1028\n",
            "Epoch 28/100\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.1023\n",
            "Epoch 29/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1022\n",
            "Epoch 30/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1028\n",
            "Epoch 31/100\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.1018\n",
            "Epoch 32/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1021\n",
            "Epoch 33/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1019\n",
            "Epoch 34/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1014\n",
            "Epoch 35/100\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.1017\n",
            "Epoch 36/100\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.1019\n",
            "Epoch 37/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1021\n",
            "Epoch 38/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1021\n",
            "Epoch 39/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1014\n",
            "Epoch 40/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1011\n",
            "Epoch 41/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1019\n",
            "Epoch 42/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1017\n",
            "Epoch 43/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1013\n",
            "Epoch 44/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1018\n",
            "Epoch 45/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1012\n",
            "Epoch 46/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1012\n",
            "Epoch 47/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1009\n",
            "Epoch 48/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1015\n",
            "Epoch 49/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1016\n",
            "Epoch 50/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1009\n",
            "Epoch 51/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1010\n",
            "Epoch 52/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1011\n",
            "Epoch 53/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1008\n",
            "Epoch 54/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1010\n",
            "Epoch 55/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1004\n",
            "Epoch 56/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1009\n",
            "Epoch 57/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1014\n",
            "Epoch 58/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1007\n",
            "Epoch 59/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1002\n",
            "Epoch 60/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1010\n",
            "Epoch 61/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1007\n",
            "Epoch 62/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1000\n",
            "Epoch 63/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1011\n",
            "Epoch 64/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1007\n",
            "Epoch 65/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1003\n",
            "Epoch 66/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1009\n",
            "Epoch 67/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1007\n",
            "Epoch 68/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1004\n",
            "Epoch 69/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0998\n",
            "Epoch 70/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1002\n",
            "Epoch 71/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1004\n",
            "Epoch 72/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1001\n",
            "Epoch 73/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0998\n",
            "Epoch 74/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0998\n",
            "Epoch 75/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1000\n",
            "Epoch 76/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1002\n",
            "Epoch 77/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0995\n",
            "Epoch 78/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1003\n",
            "Epoch 79/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0996\n",
            "Epoch 80/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0992\n",
            "Epoch 81/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1004\n",
            "Epoch 82/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0992\n",
            "Epoch 83/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0992\n",
            "Epoch 84/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1004\n",
            "Epoch 85/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0991\n",
            "Epoch 86/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0993\n",
            "Epoch 87/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0996\n",
            "Epoch 88/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0996\n",
            "Epoch 89/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0989\n",
            "Epoch 90/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0989\n",
            "Epoch 91/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0988\n",
            "Epoch 92/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0990\n",
            "Epoch 93/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0986\n",
            "Epoch 94/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0988\n",
            "Epoch 95/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0982\n",
            "Epoch 96/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0983\n",
            "Epoch 97/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0983\n",
            "Epoch 98/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0978\n",
            "Epoch 99/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0982\n",
            "Epoch 100/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0981\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Train Score: 7.79 MSE\n",
            "Test Score: 7.96 MSE\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv(\"num4.csv\")\n",
        "\n",
        "# MinMaxスケーリングを使用してデータを0〜1の範囲に正規化\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(df[['numA', 'numB', 'numC', 'numD']])\n",
        "\n",
        "# 訓練データとテストデータの作成\n",
        "train_size = int(len(scaled_data) * 0.67)\n",
        "test_size = len(scaled_data) - train_size\n",
        "train, test = scaled_data[0:train_size, :], scaled_data[train_size:len(scaled_data), :]\n",
        "\n",
        "# X=t and Y=t+1の形式にデータを変換\n",
        "def create_dataset(dataset):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-1):\n",
        "        dataX.append(dataset[i])\n",
        "        dataY.append(dataset[i + 1])\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "trainX, trainY = create_dataset(train)\n",
        "testX, testY = create_dataset(test)\n",
        "\n",
        "# LSTMの入力に合わせてデータの形状を変更\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "\n",
        "# LSTMモデルの構築\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(1, 4)))  # 50はLSTMのユニット数, 4は特徴量の数\n",
        "model.add(Dense(4))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# モデルの訓練\n",
        "model.fit(trainX, trainY, epochs=100, batch_size=1)\n",
        "\n",
        "# 予測の実行\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "# 元のスケールに戻す\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "trainY = scaler.inverse_transform(trainY)\n",
        "testPredict = scaler.inverse_transform(testPredict)\n",
        "testY = scaler.inverse_transform(testY)\n",
        "\n",
        "# 評価 (ここではMSEを計算)\n",
        "trainScore = mean_squared_error(trainY, trainPredict)\n",
        "print(f'Train Score: {trainScore:.2f} MSE')\n",
        "testScore = mean_squared_error(testY, testPredict)\n",
        "print(f'Test Score: {testScore:.2f} MSE')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ...\n",
        "\n",
        "# モデルの訓練後の部分に以下のコードを追加\n",
        "\n",
        "# round105のデータを入力として次のroundの予測を行う\n",
        "last_data = scaled_data[-1].reshape(1, 1, 4)  # 最後のデータを取得し、LSTMの入力形式に変換\n",
        "predicted_round106 = model.predict(last_data)\n",
        "\n",
        "# 予測結果を元のスケールに変換\n",
        "predicted_round106 = scaler.inverse_transform(predicted_round106)\n",
        "\n",
        "print(f'Predicted for round106: numA={predicted_round106[0][0]:.2f}, numB={predicted_round106[0][1]:.2f}, numC={predicted_round106[0][2]:.2f}, numD={predicted_round106[0][3]:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8juVz6TD-W4",
        "outputId": "8d101095-dfe4-4def-8237-ebd08af39697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predicted for round106: numA=5.20, numB=4.40, numC=5.05, numD=4.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_round(data, round_number):\n",
        "    # LSTMの入力形式に変換\n",
        "    input_data = data.reshape(1, 1, 4)\n",
        "    predicted_data = model.predict(input_data)\n",
        "\n",
        "    # 予測結果を元のスケールに変換\n",
        "    predicted_data = scaler.inverse_transform(predicted_data)\n",
        "\n",
        "    print(f'Predicted for round{round_number}: numA={predicted_data[0][0]:.2f}, numB={predicted_data[0][1]:.2f}, numC={predicted_data[0][2]:.2f}, numD={predicted_data[0][3]:.2f}')\n",
        "\n",
        "# round89の予測\n",
        "round88_data = scaled_data[87]  # 0-based indexなので、88th entryはindex 87\n",
        "predict_next_round(round88_data, 89)\n",
        "\n",
        "# round100の予測\n",
        "round99_data = scaled_data[98]  # 0-based indexなので、99th entryはindex 98\n",
        "predict_next_round(round99_data, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybgv-yjuFV-E",
        "outputId": "5642bc75-8502-49e8-aaff-b6a1a932be58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "Predicted for round89: numA=3.38, numB=5.73, numC=4.53, numD=4.81\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Predicted for round100: numA=6.75, numB=3.05, numC=4.80, numD=4.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TTy1wT3cD-F_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GRU"
      ],
      "metadata": {
        "id": "2f-IJDKWGPzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.layers import GRU\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv(\"num4.csv\")\n",
        "\n",
        "# MinMaxスケーリングを使用してデータを0〜1の範囲に正規化\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(df[['numA', 'numB', 'numC', 'numD']])\n",
        "\n",
        "# 訓練データとテストデータの作成\n",
        "train_size = int(len(scaled_data) * 0.67)\n",
        "test_size = len(scaled_data) - train_size\n",
        "train, test = scaled_data[0:train_size, :], scaled_data[train_size:len(scaled_data), :]\n",
        "\n",
        "# X=t and Y=t+1の形式にデータを変換\n",
        "def create_dataset(dataset):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-1):\n",
        "        dataX.append(dataset[i])\n",
        "        dataY.append(dataset[i + 1])\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "trainX, trainY = create_dataset(train)\n",
        "testX, testY = create_dataset(test)\n",
        "\n",
        "# GRUの入力に合わせてデータの形状を変更\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "\n",
        "# GRUモデルの構築\n",
        "model = Sequential()\n",
        "model.add(GRU(50, input_shape=(1, 4)))  # ここでLSTMの代わりにGRUを使用\n",
        "model.add(Dense(4))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# モデルの訓練\n",
        "model.fit(trainX, trainY, epochs=100, batch_size=1)\n",
        "\n",
        "# 予測の実行\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "# 元のスケールに戻す\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "trainY = scaler.inverse_transform(trainY)\n",
        "testPredict = scaler.inverse_transform(testPredict)\n",
        "testY = scaler.inverse_transform(testY)\n",
        "\n",
        "# 評価 (ここではMSEを計算)\n",
        "trainScore = mean_squared_error(trainY, trainPredict)\n",
        "print(f'Train Score: {trainScore:.2f} MSE')\n",
        "testScore = mean_squared_error(testY, testPredict)\n",
        "print(f'Test Score: {testScore:.2f} MSE')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYMoOXzwGv58",
        "outputId": "92b09d24-5b9d-494f-ddb2-0353f2d7ed2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "69/69 [==============================] - 4s 6ms/step - loss: 0.1807\n",
            "Epoch 2/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1218\n",
            "Epoch 3/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1181\n",
            "Epoch 4/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1162\n",
            "Epoch 5/100\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.1135\n",
            "Epoch 6/100\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.1121\n",
            "Epoch 7/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1107\n",
            "Epoch 8/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1102\n",
            "Epoch 9/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1095\n",
            "Epoch 10/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1073\n",
            "Epoch 11/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1064\n",
            "Epoch 12/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1070\n",
            "Epoch 13/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1057\n",
            "Epoch 14/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1058\n",
            "Epoch 15/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1058\n",
            "Epoch 16/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1043\n",
            "Epoch 17/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1043\n",
            "Epoch 18/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1043\n",
            "Epoch 19/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1048\n",
            "Epoch 20/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1028\n",
            "Epoch 21/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1045\n",
            "Epoch 22/100\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.1037\n",
            "Epoch 23/100\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.1049\n",
            "Epoch 24/100\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.1025\n",
            "Epoch 25/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1024\n",
            "Epoch 26/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1034\n",
            "Epoch 27/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1033\n",
            "Epoch 28/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1043\n",
            "Epoch 29/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1033\n",
            "Epoch 30/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1035\n",
            "Epoch 31/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1027\n",
            "Epoch 32/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1033\n",
            "Epoch 33/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1038\n",
            "Epoch 34/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1035\n",
            "Epoch 35/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1024\n",
            "Epoch 36/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1021\n",
            "Epoch 37/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1037\n",
            "Epoch 38/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1026\n",
            "Epoch 39/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1020\n",
            "Epoch 40/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1024\n",
            "Epoch 41/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1022\n",
            "Epoch 42/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1024\n",
            "Epoch 43/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1029\n",
            "Epoch 44/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1016\n",
            "Epoch 45/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1025\n",
            "Epoch 46/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1028\n",
            "Epoch 47/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1018\n",
            "Epoch 48/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1019\n",
            "Epoch 49/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1022\n",
            "Epoch 50/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1024\n",
            "Epoch 51/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1016\n",
            "Epoch 52/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.1022\n",
            "Epoch 53/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1013\n",
            "Epoch 54/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1017\n",
            "Epoch 55/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1013\n",
            "Epoch 56/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.1026\n",
            "Epoch 57/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1020\n",
            "Epoch 58/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.1020\n",
            "Epoch 59/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1018\n",
            "Epoch 60/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1016\n",
            "Epoch 61/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.1028\n",
            "Epoch 62/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1014\n",
            "Epoch 63/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1017\n",
            "Epoch 64/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1006\n",
            "Epoch 65/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1018\n",
            "Epoch 66/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1010\n",
            "Epoch 67/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.1013\n",
            "Epoch 68/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1018\n",
            "Epoch 69/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1024\n",
            "Epoch 70/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1013\n",
            "Epoch 71/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1008\n",
            "Epoch 72/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.1010\n",
            "Epoch 73/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.1011\n",
            "Epoch 74/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.1013\n",
            "Epoch 75/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1018\n",
            "Epoch 76/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.1017\n",
            "Epoch 77/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.1007\n",
            "Epoch 78/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.1005\n",
            "Epoch 79/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1006\n",
            "Epoch 80/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1010\n",
            "Epoch 81/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1011\n",
            "Epoch 82/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.1005\n",
            "Epoch 83/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1003\n",
            "Epoch 84/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1000\n",
            "Epoch 85/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.1005\n",
            "Epoch 86/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1006\n",
            "Epoch 87/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1002\n",
            "Epoch 88/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1020\n",
            "Epoch 89/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1012\n",
            "Epoch 90/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1003\n",
            "Epoch 91/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0997\n",
            "Epoch 92/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0999\n",
            "Epoch 93/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1000\n",
            "Epoch 94/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1002\n",
            "Epoch 95/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0996\n",
            "Epoch 96/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1008\n",
            "Epoch 97/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0999\n",
            "Epoch 98/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0990\n",
            "Epoch 99/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0990\n",
            "Epoch 100/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0999\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Train Score: 7.93 MSE\n",
            "Test Score: 8.12 MSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_round(data, round_number):\n",
        "    # GRUの入力形式に変換\n",
        "    input_data = data.reshape(1, 1, 4)\n",
        "    predicted_data = model.predict(input_data)\n",
        "\n",
        "    # 予測結果を元のスケールに変換\n",
        "    predicted_data = scaler.inverse_transform(predicted_data)\n",
        "\n",
        "    print(f'Predicted for round{round_number}: numA={predicted_data[0][0]:.2f}, numB={predicted_data[0][1]:.2f}, numC={predicted_data[0][2]:.2f}, numD={predicted_data[0][3]:.2f}')\n",
        "\n",
        "# round89の予測\n",
        "round88_data = scaled_data[87]  # 0-based indexなので、88th entryはindex 87\n",
        "predict_next_round(round88_data, 89)\n",
        "\n",
        "# round100の予測\n",
        "round99_data = scaled_data[98]  # 0-based indexなので、99th entryはindex 98\n",
        "predict_next_round(round99_data, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNMMBpo_GpyF",
        "outputId": "0d670253-499d-4368-e73d-eaad89b686d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "Predicted for round89: numA=3.45, numB=5.29, numC=4.41, numD=4.80\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Predicted for round100: numA=6.41, numB=3.05, numC=4.67, numD=4.56\n"
          ]
        }
      ]
    }
  ]
}